# Reducing the Carbon Footprint of Microservice-Based Cloud Applications by Periodically Scaling their Energy Demand


# Experiments
There are in total 32 different experiments that were conducted for each algorithm (the proposed selective optimization algorithm, the high-performance baseline, the simple carbon-aware baseline and the sequential carbon-aware baseline) and they can be executed by running the following PY files, that can be found in the "experiments" folder:
1. optimizedCarbonAware.py (to run the experiments for the selective optimization algorithm)
2. highPerformanceBaseline.py (to run the experiments for the high-performance baseline)
3. simpleCarbonAwareBaseline.py (to run the experiments for the simple carbon-aware baseline)
4. sequentialCarbonAwareBaseline.py (to run the experiments for the selective optimization algorithm)


# Results
The results of the experiments can be found in the form of CSV files in the "results" folder. In this folder there are 4 sub-folders:
1. HH
2. HL
3. LH
4. LL
   
These folders contain the results of the experiments that take as input the JSON files flightBooking_HH.json, flightBooking_HL.json, flightBooking_LH.json and flightBooking_LL.json, respectively, that correspond to four different configurations for the application. These results are contained into furhter sub-fodlers, which divide them by algorithm, and consist of 8 files (one for each carbon budget), except for the high-performance baseline, which is a single CSV file (given that its results are independent from the budget used).

# Visualization
In the "visualization" folder there are the Jupyter Notebooks used to generate graphs about the resulting data, which are stored in the "img" folder.


# Data 

## Data Sources
The data used for the experiments can be found in the "data" folder.  
It consists of the following data sets:
- Carbon Intensity Data from [Electricity Maps](https://www.electricitymaps.com/data-portal) for Germany
  - DE_2020.csv
  - DE_2021.csv
- User-Request Data from [Wikimedia ](https://dumps.wikimedia.org/other/pagecounts-raw/)
  - projectcount_wikiDE_2014.csv
  - projectcount_wikiDE_2015.csv
- Carbon budgets in input
  - CB_adaptive.csv
  - CB_constant.csv

The carbon intensity data is licensed under [ODbl](https://opendatacommons.org/licenses/odbl/).  
The wikimedia pageview dataset is licensed under [Creative Commons Zero (CC0) public domain dedication](https://creativecommons.org/publicdomain/zero/1.0/) as it is part of the [Wikimedia: Analytics Datasets](https://dumps.wikimedia.org/other/analytics/), whose license is stated in [https://dumps.wikimedia.org/legal.html](https://dumps.wikimedia.org/legal.html).

The carbon budgets are generated by running the PY file inputGeneration.py, in the "experiments" folder.

## Application Data
The data for the application architecture of the flight booking use case is stored in 4 JSON files: 
1. flightBooking_HH.json
2. flightBooking_HL.json 
3. flightBooking_LH.json 
4. flightBooking_LL.json

The last two letters of these files stand either for "high" (H) or "low" (L). The first of the two letters indicates if higher (H) or lower (L) values are used for the parameter uc (the number of users that a single instance of each microservice can handle), while the second has the same meaning for parameter "QoE" (the quality of experience associated with the execution formats of the various microserivces).

#  How to run the experiments

## Requirements
In order to run the experiments, the following requirements need to be met:  
- Python 3.9.12
  - [Requirements](requirements.txt)
- [Gurobi Optimizer](https://www.gurobi.com/) (for the mathematical optimum solution): a license is needed
  - An academic license can be obtained [here](https://www.gurobi.com/academia/academic-program-and-licenses/).

## Installation of the python environment
We advise to use a virtual environment, such as [Anaconda](https://www.anaconda.com/).  
If you do not have Anaconda installed, you can download it [here](https://www.anaconda.com/products/individual).
With Anaconda and the following commands, it can be ensured that the same environment is used for the experiments:
```bash
conda create --name <env-name> python=3.9.12
conda activate <env-name>
conda install gurobi
pip install -r requirements.txt
```

To leave your conda envrionment again you can use the following command:
```bash
conda deactivate
```


## Acitvating the Gurobi License
The Gurobi license has to be activated before the experiments can be run.
```bash
grbgetkey <license-key>
```


# Library of functions
The [lib.py](lib.py) file contains all the functions used in multiple experiments.

